{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlos-Oliver-O/Carlos-Oliver-O/blob/main/01_DataFramesBascis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3WKxUMvQ9JW"
      },
      "source": [
        "# DataFrames Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBsRl4yARA3x"
      },
      "source": [
        "## Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KID1ObYRDA4"
      },
      "source": [
        "Install Spark and Java in VM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9EjQzqhRJSZ",
        "outputId": "b58deecf-5c23-4513-9e6d-6f31651c75d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/q: Scheme missing.\n",
            "--2024-12-03 17:29:25--  https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400864419 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.3-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.3-bin-had 100%[===================>] 382.29M   184MB/s    in 2.1s    \n",
            "\n",
            "2024-12-03 17:29:28 (184 MB/s) - ‘spark-3.5.3-bin-hadoop3.tgz’ saved [400864419/400864419]\n",
            "\n",
            "FINISHED --2024-12-03 17:29:28--\n",
            "Total wall clock time: 2.2s\n",
            "Downloaded: 1 files, 382M in 2.1s (184 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark 3.5.3\n",
        "!wget /q https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4s6wcUsSPHQ",
        "outputId": "e3c21632-884b-4ebc-a9c1-5d7071b4fc83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 391476\n",
            "drwxr-xr-x 1 root root      4096 Nov 25 19:13 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 400864419 Sep  9 05:35 spark-3.5.3-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "ls -l # check the .tgz is there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hSA_T2q7SEt_"
      },
      "outputs": [],
      "source": [
        "# unzip it\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HpKEfJTeii2Y"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwH-zC17SGnP",
        "outputId": "75867ed3-631d-4559-b76d-6a3a585051c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2024.8.30)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install py4j\n",
        "\n",
        "# For maps\n",
        "!pip install folium\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1tk452JRjuY"
      },
      "source": [
        "Define the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vrMxCiuZRl7h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk_3rL02Q9JZ"
      },
      "source": [
        "Start Spark Session\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-HtQz6mfQ9JZ"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-3.5.3-bin-hadoop3\")# SPARK_HOME\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"DataFrames Basics\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "DrOjmfL9Q9Ja",
        "outputId": "10b672f5-3ba4-47a3-c689-dfcdf6043fcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x789f115ef310>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://733cf91fbd66:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DataFrames Basics</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IBZ8ufPAQ9Jb"
      },
      "outputs": [],
      "source": [
        "# For Pandas conversion optimization\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nJ-cdrAlQ9Jb"
      },
      "outputs": [],
      "source": [
        "# Import sql functions\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIP7U3YYTDbw"
      },
      "source": [
        "Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d63cazZLTKTv",
        "outputId": "fef75e20-bda0-47c1-f139-8562480de079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank.csv  cars.json  movies.json  vehicles.csv\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p dataset\n",
        "!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2324/master/dataset/cars.json -P /dataset\n",
        "!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2324/master/dataset/movies.json -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n",
        "!ls /dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml1O2OiQU6ah",
        "outputId": "8539d2a5-e0e8-4ede-8315-7633075d42c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1784\n",
            "-rw-r--r-- 1 root root  461474 Dec  3 17:30 bank.csv\n",
            "-rw-r--r-- 1 root root   74910 Dec  3 17:30 cars.json\n",
            "-rw-r--r-- 1 root root 1274347 Dec  3 17:30 movies.json\n",
            "-rw-r--r-- 1 root root    4370 Dec  3 17:30 vehicles.csv\n"
          ]
        }
      ],
      "source": [
        "ls -l /dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94aRTBiPQ9Jc"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XxXiDT4XUgjl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import Row\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p69TjjJBTrDF",
        "outputId": "180f35f5-b4bd-4dd1-ab19-030db49bac4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+---------+-------+\n",
            "|age|       job|marital|education|balance|\n",
            "+---+----------+-------+---------+-------+\n",
            "| 30|unemployed|married|  primary|   1787|\n",
            "| 33|  services|married|secondary|   4789|\n",
            "| 35|management| single| tertiary|   1350|\n",
            "+---+----------+-------+---------+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bankText = spark.sparkContext.textFile(\"/dataset/bank.csv\")\n",
        "\n",
        "#we have to: remove first row (headers), map the rest, and create DF\n",
        "bank = bankText.map(lambda lineaCsv: lineaCsv.split(\";\"))\\\n",
        ".filter(lambda s: s[0] != \"\\\"age\\\"\") \\\n",
        ".map(lambda row: Row(int(row[0]), row[1].replace(\"\\\"\", \"\"), row[2].replace(\"\\\"\", \"\"), row[3].replace(\"\\\"\", \"\"), row[5].replace(\"\\\"\", \"\"))) \\\n",
        ".toDF([\"age\", \"job\", \"marital\", \"education\", \"balance\"]) \\\n",
        ".withColumn(\"age\", col(\"age\").cast(\"int\"))\n",
        "\n",
        "bank.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnCG9XHsTUfe"
      },
      "source": [
        "Read directly from JSON file to a DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iBWBcsLDTYuF"
      },
      "outputs": [],
      "source": [
        "carsDF = spark.read.option(\"inferSchema\", True).json(\"/dataset/cars.json\") # inferSchema requires one extra pass over the data\n",
        "\n",
        "# if None is set, it uses de default value (default = False) you can also pass the schema manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beN35oUrUo4c"
      },
      "source": [
        "Read directly from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaxDO13vUlSs",
        "outputId": "3d27fce6-eeb0-4813-da6d-b16509fa0a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|       job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 30|unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
            "| 33|  services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
            "| 35|management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bankDF = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").csv(\"/dataset/bank.csv\")\n",
        "bankDF.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOt52pbaQ9Jc"
      },
      "source": [
        "Showing a DF and print schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmmsrRxaQ9Jd",
        "outputId": "aabfc8a5-d10d-4619-f8e4-53a28f484aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year|\n",
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01|\n",
            "|        11.5|        8|       350.0|       165|            15.0|   buick skylark 320|   USA|         3693|1970-01-01|\n",
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "only showing top 2 rows\n",
            "\n",
            "root\n",
            " |-- Acceleration: double (nullable = true)\n",
            " |-- Cylinders: long (nullable = true)\n",
            " |-- Displacement: double (nullable = true)\n",
            " |-- Horsepower: long (nullable = true)\n",
            " |-- Miles_per_Gallon: double (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            " |-- Weight_in_lbs: long (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "carsDF.show(2)\n",
        "carsDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij4TDMZ0lkBZ"
      },
      "source": [
        "Get Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB06W84wlnlY",
        "outputId": "06752556-e700-4c23-97a3-9946a1c6e57d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Acceleration=12.0, Cylinders=8, Displacement=307.0, Horsepower=130, Miles_per_Gallon=18.0, Name='chevrolet chevelle malibu', Origin='USA', Weight_in_lbs=3504, Year='1970-01-01'),\n",
              " Row(Acceleration=11.5, Cylinders=8, Displacement=350.0, Horsepower=165, Miles_per_Gallon=15.0, Name='buick skylark 320', Origin='USA', Weight_in_lbs=3693, Year='1970-01-01')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "carsDF.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89eHF1aQ9Jd"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtFilGlZWGyo",
        "outputId": "ffae4f03-1365-4071-8073-553dda885b38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "406"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "carsDF.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akmA70EPQ9Jd"
      },
      "source": [
        "Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp6hKanzQ9Je",
        "outputId": "995d7ebd-c463-4d29-a3e8-443e640efd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.types.StructType'>\n",
            "StructType([StructField('Acceleration', DoubleType(), True), StructField('Cylinders', LongType(), True), StructField('Displacement', DoubleType(), True), StructField('Horsepower', LongType(), True), StructField('Miles_per_Gallon', DoubleType(), True), StructField('Name', StringType(), True), StructField('Origin', StringType(), True), StructField('Weight_in_lbs', LongType(), True), StructField('Year', StringType(), True)])\n"
          ]
        }
      ],
      "source": [
        "# obtain a schema\n",
        "carsSchema = carsDF.schema\n",
        "print(type(carsSchema))\n",
        "print(carsSchema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_XS0vB0Q9Je"
      },
      "source": [
        "Custom Schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ekQkJLT8Q9Je"
      },
      "outputs": [],
      "source": [
        "example = spark.sparkContext.parallelize([(\"chevrolet chevelle malibu\",18,\"1970-01-01\",\"USA\"),\n",
        "    (\"buick skylark 320\",15,\"1970-01-01\",\"USA\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUzjX4kTQ9Je",
        "outputId": "c8d0af21-7f0a-4de0-bb70-6874e1a39f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            " |-- _3: string (nullable = true)\n",
            " |-- _4: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exampleDF = spark.createDataFrame(example)\n",
        "exampleDF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfAtq2qVMsWP",
        "outputId": "2267863d-d856-44db-d011-ec3a36ffa990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---+----------+---+\n",
            "|                  _1| _2|        _3| _4|\n",
            "+--------------------+---+----------+---+\n",
            "|chevrolet chevell...| 18|1970-01-01|USA|\n",
            "|   buick skylark 320| 15|1970-01-01|USA|\n",
            "+--------------------+---+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exampleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeTtjRirQ9Je"
      },
      "source": [
        "With columns names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uhY-f3j1Q9Jf"
      },
      "outputs": [],
      "source": [
        "names = list([\"name\", \"weight\", \"date\", \"country\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqxqPyr1Q9Jf",
        "outputId": "ba94722a-0c54-4ed9-a9d2-f0f0f169e3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- weight: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example2DF = example.toDF(names)\n",
        "example2DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMHUSFgTMxe6",
        "outputId": "1bdb67ed-76f6-4d36-f821-15fa83d83669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+----------+-------+\n",
            "|                name|weight|      date|country|\n",
            "+--------------------+------+----------+-------+\n",
            "|chevrolet chevell...|    18|1970-01-01|    USA|\n",
            "|   buick skylark 320|    15|1970-01-01|    USA|\n",
            "+--------------------+------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example2DF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "toUIbosSQ9Jf"
      },
      "outputs": [],
      "source": [
        "# importing sql types\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KZNfLhFWQ9Jf"
      },
      "outputs": [],
      "source": [
        "# custom schema\n",
        "customSchema = StructType([ \\\n",
        "    StructField('name', StringType(), True), \\\n",
        "    StructField('weight', StringType(), True), \\\n",
        "    StructField('date', StringType(), True), \\\n",
        "    StructField('country', StringType(), True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x63bbTDYQ9Jf",
        "outputId": "cbe0b0c5-f74d-43a4-ac32-efddcd604223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- weight: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example3DF = spark.createDataFrame(example, customSchema)\n",
        "example3DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRiqa-G5Q9Jf",
        "outputId": "1d8e4ff7-5b44-4991-ae55-969acb2b6b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+------+----------+-------+\n",
            "|name                     |weight|date      |country|\n",
            "+-------------------------+------+----------+-------+\n",
            "|chevrolet chevelle malibu|18    |1970-01-01|USA    |\n",
            "|buick skylark 320        |15    |1970-01-01|USA    |\n",
            "+-------------------------+------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example3DF.show(2, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "M3qToymLQ9Jg"
      },
      "outputs": [],
      "source": [
        "# we can also specify schema with DDL (Data Definition Language)\n",
        "customSchema2 = \"`name` STRING NOT NULL, `weight` INT, `date` STRING, `country` STRING\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k9X1gSSQ9Jg",
        "outputId": "ef6d1fe8-cd7a-434e-89fb-21813988994d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = false)\n",
            " |-- weight: integer (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example4DF = spark.createDataFrame(example, customSchema2)\n",
        "example4DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rayh3uQ9Jg",
        "outputId": "36e4a0ac-7dff-466c-a112-62879795ef51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "print(type(example2DF.collect()[0][\"weight\"]))\n",
        "print(type(example3DF.collect()[0][\"weight\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QnciaoWQ9Jg"
      },
      "source": [
        "## Exercises\n",
        "1) Create a manual DF describing smartphones\n",
        "  - maker\n",
        "  - model\n",
        "  - screen dimension\n",
        "  - camera megapixels\n",
        "  \n",
        "2) Read another file from the dataset/ folder, e.g. movies.json\n",
        "  - print its schema\n",
        "  - count the number of rows, call count()\n",
        "\n",
        "3) Take a look to vehicles.csv. Read the file to a DF but this time with your own schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQR1cduXQ9Jg"
      },
      "source": [
        "Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = spark.sparkContext.parallelize([(\"Iphone\",14,\"10x10\",\"64mpx\"),\n",
        "    (\"buick skylark 320\",15,\"1970-01-01\",\"USA\"), (\"Iphone\",14,\"10x10\",\"64mpx\")])"
      ],
      "metadata": {
        "id": "tduHHel1rNOz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = list([\"maker\", \"model\", \"screen dimension\", \"camera megapixels\"])\n",
        "ejer1_DF = example.toDF(names)\n",
        "ejer1_DF.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQlCTL6jqQM0",
        "outputId": "047dded8-f5e4-4579-b5fe-fd1fc6455cf5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- maker: string (nullable = true)\n",
            " |-- model: long (nullable = true)\n",
            " |-- screen dimension: string (nullable = true)\n",
            " |-- camera megapixels: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejer1_DF.show(3, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNh19eO8p-vH",
        "outputId": "aba103f8-0d16-44b6-c539-e1a4d389248b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------------+-----------------+\n",
            "|maker            |model|screen dimension|camera megapixels|\n",
            "+-----------------+-----+----------------+-----------------+\n",
            "|Iphone           |14   |10x10           |64mpx            |\n",
            "|buick skylark 320|15   |1970-01-01      |USA              |\n",
            "|Iphone           |14   |10x10           |64mpx            |\n",
            "+-----------------+-----+----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejer1_DF.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDWaXi9Nq0US",
        "outputId": "6135394a-9f12-4b58-a49b-d66f63357d7d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmg5kbOpl-s3"
      },
      "source": [
        "Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2\n",
        "moviesDF = spark.read.option(\"inferSchema\", True).json(\"/dataset/movies.json\")\n",
        "moviesDF.printSchema()\n",
        "print(f\"Number of rows: {moviesDF.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyhJlic3nkGO",
        "outputId": "80b1d939-9dbf-4782-bb69-39acb9120922"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Creative_Type: string (nullable = true)\n",
            " |-- Director: string (nullable = true)\n",
            " |-- Distributor: string (nullable = true)\n",
            " |-- IMDB_Rating: double (nullable = true)\n",
            " |-- IMDB_Votes: long (nullable = true)\n",
            " |-- MPAA_Rating: string (nullable = true)\n",
            " |-- Major_Genre: string (nullable = true)\n",
            " |-- Production_Budget: long (nullable = true)\n",
            " |-- Release_Date: string (nullable = true)\n",
            " |-- Rotten_Tomatoes_Rating: long (nullable = true)\n",
            " |-- Running_Time_min: long (nullable = true)\n",
            " |-- Source: string (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- US_DVD_Sales: long (nullable = true)\n",
            " |-- US_Gross: long (nullable = true)\n",
            " |-- Worldwide_Gross: long (nullable = true)\n",
            "\n",
            "Number of rows: 3201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAqADV5jW00d"
      },
      "source": [
        "Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JD2KQtXiYmVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6f33b2-1cc1-473a-9d82-ee476f5d1739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Car: string (nullable = true)\n",
            " |-- MPG: double (nullable = true)\n",
            " |-- Cylinders: integer (nullable = true)\n",
            " |-- Displacement: double (nullable = true)\n",
            " |-- Horsepower: double (nullable = true)\n",
            " |-- Weight: integer (nullable = true)\n",
            " |-- Acceleration: double (nullable = true)\n",
            " |-- Model: integer (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            "\n",
            "+------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|               Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|      Sand Crawler|NULL|     NULL|    150000.0|      36.8|    30|        46.0|   30| 50000|\n",
            "|    T-16 skyhopper|NULL|     NULL|     14500.0|      10.4|  1200|         1.0|    1|    50|\n",
            "|  X-34 landspeeder|NULL|     NULL|     10550.0|       3.4|   250|         1.0|    1|     5|\n",
            "|TIE/LN starfighter|NULL|     NULL|        NULL|       6.4|  1200|         1.0|    0|    65|\n",
            "|       Snowspeeder|NULL|     NULL|        NULL|       4.5|   650|         2.0|    0|    10|\n",
            "+------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vehicleSchema = StructType([\n",
        "    StructField(\"Car\", StringType(), True),\n",
        "    StructField(\"MPG\", DoubleType(), True),\n",
        "    StructField(\"Cylinders\", IntegerType(), True),\n",
        "    StructField(\"Displacement\", DoubleType(), True),\n",
        "    StructField(\"Horsepower\", DoubleType(), True),\n",
        "    StructField(\"Weight\", IntegerType(), True),\n",
        "    StructField(\"Acceleration\", DoubleType(), True),\n",
        "    StructField(\"Model\", IntegerType(), True),\n",
        "    StructField(\"Origin\", StringType(), True)\n",
        "])\n",
        "\n",
        "vehiclesDF = spark.read.csv(\"/dataset/vehicles.csv\", header=True, schema=vehicleSchema)\n",
        "\n",
        "vehiclesDF.printSchema()\n",
        "vehiclesDF.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cPCYVHm4r_A_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}